# optional annotation overrides
global:
  ingress:
    annotations: {}

# A place to define a healthcheck path or other grafana specific annotations
grafanaIngress:
  annotations: {}

# A place to define a healthcheck path or other prometheus specific
# annotations
prometheusIngress:
  annotations: {}

grafana:
  adminUser: admin
  fullnameOverride: monitoring-grafana
  # An adminPassword must be set
  # adminPassword: {password}

  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          url: http://monitoring-prometheus-server
          access: proxy
          isDefault: true
  service:
    enabled: true
    type: NodePort
  sidecar:
    dashboards:
      enabled: true

  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: "default"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default
        - name: "kube"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/kube
        - name: "urbanos"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/urbanos
  dashboards:
    kube:
      kube-prometheus:
        gnetId: 2
        revision: 2
        datasource: Prometheus
      kube-namespace:
        gnetId: 6876
        revision: 2
        datasource: Prometheus
      kube-cluster:
        gnetId: 6873
        revision: 2
        datasource: Prometheus
      kube-pods:
        gnetId: 6879
        revision: 1
        datasource: Prometheus
    urbanos:
      urban-os-pipeline-health:
        gnetId: 14805
        revision: 1
        datasource: Prometheus
      urban-os-overview:
        gnetId: 14806
        revision: 1
        datasource: Prometheus
      urban-os-kube-all-nodes:
        gnetId: 14810
        revision: 1
        datasource: Prometheus
      urban-os-kafka-exporter:
        gnetId: 14809
        revision: 1
        datasource: Prometheus
      urban-os-phoenix-api-metrics:
        gnetId: 14811
        revision: 1
        datasource: Prometheus
    # Additional deployment specific dashboards may be
    # added under the "default" provider:
    # default:
    #   custom-dashboard-name:
    #     gnetId: 14811 (dashboard id from https://grafana.com/grafana/dashboards)
    #     revision: 1
    #     datasource: Prometheus

prometheus:
  server:
    fullnameOverride: monitoring-prometheus-server
    resources:
      limits:
        memory: 1Gi
        cpu: 500m
      requests:
        memory: 1Gi
        cpu: 500m
    service:
      type: NodePort
  serverFiles:
    # Any additional alerts can go here, and will be combined with alerting_rules
    alerts: {}

    rules:
      groups:
        - name: pipeline.rules
          interval: 30s
          rules:
            - expr: label_replace(label_replace(sum(rate(kafka_topic_partition_current_offset[2m]) > 0) by (topic), "dataset_id", "$2", "topic", "(raw|transformed)-(.*)"), "stage", "$1", "topic", "(raw|transformed)-(.*)") * on (dataset_id) group_left(dataset_title, source_type, org_name) dataset_info_gauge
              record: "pipeline:topic:throughput"
            - expr: label_replace(label_replace(label_replace(sum(kafka_consumergroup_lag{consumergroup!~"console.*"} > 0) by (consumergroup, topic, dataset), "dataset_id", "$3", "consumergroup", "(.+)-(raw|transformed)-(.*)"), "stage", "$2", "consumergroup", "(.+)-(raw|transformed)-(.*)"), "app", "$1", "consumergroup", "(.+)-(raw|transformed)-(.*)") * on (dataset_id) group_left(dataset_title, source_type, org_name) dataset_info_gauge
              record: "pipeline:topic:lag"
            - expr: sum(rate(events_handled_count{event_type!="data:extract:end"}[2m]) > 0) by (app, dataset_id, event_type) * on (dataset_id) group_left(dataset_title, source_type, org_name) dataset_info_gauge
              record: "pipeline:event_stream:events_handled"
            - expr: label_replace(kafka_consumergroup_lag{consumergroup=~"(.*event-stream|.*events)"}, "app", "$1", "consumergroup", "(.+)-(event-stream|events)") > 0
              record: "pipeline:event_stream:lag"
            - expr: sum(label_replace(rate(fluentd_input_status_num_records_total{tag=~".*(forklift|reaper|voltron|valkyrie|odo|discovery-api).*"}[5m]), "name", "$1", "tag", "kube.var.log.containers.(.+?)-.*")) by (name) > 0
              record: "pipeline:log_message_rate"

    alerting_rules.yml:
      groups:
        # Blackbox probe
        - name: Sites
          rules:
            - alert: SiteDown
              expr: probe_success == 0
              for: 2m
              labels:
                severity: error
              annotations:
                description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 2 minutes."
                summary: "Instance {{ $labels.instance }} down"
        - name: api_status
          rules:
            - alert: APIStatusDown
              expr: probe_success == 0
              for: 1m
              labels:
                severity: error
              annotations:
                description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 1 minutes."
                summary: "Instance {{ $labels.instance }} down"
        - name: api_response
          rules:
            - alert: APIResponseTime
              expr: probe_duration_seconds > 3
              for: 1m
              labels:
                severity: error
              annotations:
                description: "{{ $labels.instance }} of job {{ $labels.job }} is taking more than 3 seconds."
                summary: "Instance {{ $labels.instance }} is taking longer response time"
        - name: K8S_Nodes
          rules:
            - alert: LowMemory
              expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100) < 20
              for: 5m
              labels:
                severity: warning
              annotations:
                description: "{{ $labels.instance }} has {{ $value }} percent memory left."
                summary: "Low Memory on Instance {{ $labels.instance }}"
            - alert: LowDisk
              expr: (node_filesystem_avail_bytes{device=~"/dev/.*"} / node_filesystem_size_bytes{device=~"/dev/.*"} * 100) < 15
              for: 5m
              labels:
                severity: warning
              annotations:
                description: "{{ $labels.instance }} has {{ $value }} percent disk left."
                summary: "Low Disk on Instance {{ $labels.instance }}"
            - alert: LowClusterCPU
              expr: (cluster:capacity_cpu:sum - cluster:guarantees_cpu:sum) < 1
              labels:
                severity: warning
              annotations:
                description: "Kubernetes cluster has {{ $value }} cores left. New deployments and cron jobs may fail to launch."
                summary: "Kubernetes cluster low on CPU cores"
            - alert: LowClusterMemory
              expr: (cluster:capacity_memory_bytes:sum - cluster:guarantees_memory_bytes:sum) < 1000000000 #1GB
              labels:
                severity: warning
              annotations:
                description: "Kubernetes cluster has {{ $value | humanize }} memory left. New deployments and cron jobs may fail to launch."
                summary: "Kubernetes cluster has less than {{ 1000000000.0 | humanize }} memory available"
            - alert: NotReady
              annotations:
                description: "{{ $labels.node }} is not ready"
                summary: "Status not Ready on Node {{ $labels.node }}"
              expr: kube_node_status_condition{condition="Ready", status="true"} != 1
              labels:
                severity: error
        - name: consumer_group_event_stream_lag
          rules:
            - alert: ConsumerGroupEventStreamLag
              expr: pipeline:event_stream:lag > 10000
              labels:
                severity: warning
              annotations:
                summary: "Consumer Group lag for topic {{ $labels.topic }} is greater than 10,000"
                description: "The lag for consumer group {{ $labels.consumergroup }} is {{ humanize $value }}."
        - name: low_disk_space
          rules:
            - alert: LowDiskSpace
              expr: (kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100)  < 15
              labels:
                severity: warning
              annotations:
                summary: "Server disk space is below 15%"
                description: 'Low disk space for Server {{ $labels.persistentvolumeclaim }}, only {{ $value | printf "%.2f" }}% space is left.'
        - name: rule_failure
          rules:
            - alert: RuleFailure
              expr: rate(prometheus_rule_evaluation_failures_total{rule_group=~".*rules.*"}[2m]) > 0
              labels:
                severity: warning
              annotations:
                summary: "Prometheus has failed to precalculate one or more metrics"
                description: "One of the recording rules defined in Prometheus has failed to execute. This is often due to issues with info metrics, but may have other causes. Look at the rules section of the Prometheus interface for more info."
